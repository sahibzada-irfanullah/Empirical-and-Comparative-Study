{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 20:57:30.805423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import re\n",
    "import scipy\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"22-05-06_20-59-32_Unigrams_CountVect_WRul_Freq-3803\"\n",
    "path = \"../simple_vect/\" + filename\n",
    "\n",
    "load_vect = pickle.load(open(path, 'rb'))\n",
    "# load_vect.texts_to_sequences(df[\"tweet_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'texts_to_sequences'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24466/3649686140.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mclasses_labels_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX_train_WoR_dtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mX_train_WoR_dtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_WoR_dtm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mX_train_WoR_Features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'texts_to_sequences'"
     ]
    }
   ],
   "source": [
    "fnameTrainingDataset = \"../datasets/500_random_sample.csv\"\n",
    "df = pd.read_csv(fnameTrainingDataset)\n",
    "X = df['tweet_text']\n",
    "y_binary = df['tweet_class']\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_binary = le.fit_transform(y_binary)\n",
    "\n",
    "classes_labels_binary = le.classes_\n",
    "X_train_WoR_dtm = load_vect.texts_to_sequences(X)\n",
    "X_train_WoR_dtm = pad_sequences(X_train_WoR_dtm, maxlen=20)\n",
    "X_train_WoR_Features = list(load_vect.word_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"22-04-02_23-10-18_doc2vec_Vect_WoRul_Max-Len-Seq-20_Freq-20_CNN\"\n",
    "path = \"F:/RweetMiner/RweetMinerNew/request_identification_class_DLCorrected/doc2vec_clfModels/\" + filename\n",
    "load_model = pickle.load(open(path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = load_model.predict(X_train_WoR_dtm)\n",
    "np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_regex(text, regex):\n",
    "    match_found = (re.search(regex ,text) !=None)\n",
    "    match_found = int(match_found == True)\n",
    "    return match_found\n",
    "\n",
    "def series_to_DataFrame(X_data):\n",
    "    X_data = X_data.to_frame()\n",
    "    return X_data\n",
    "\n",
    "def concat_sparse_matrices_h(data_X_dtm, data_Rules_dtm, features_X, features_Rules):\n",
    "    combined_features = features_X + features_Rules\n",
    "    concat_sparse = scipy.sparse.hstack([data_X_dtm, data_Rules_dtm], format='csr')\n",
    "    return concat_sparse, combined_features\n",
    "\n",
    "def gen_rules_features(X_data_series): # , X_data_dtm, features_arg):\n",
    "    '''sparse matrix and series matrices should be converted to dataframe for applying rules and treating\n",
    "    it as features...\n",
    "    I wrote two functions i.e.,sparse_matrix_to_DataFrame() and series_DataFrame()\n",
    "      for changing datatypes'''\n",
    "    X_data_DF = series_to_DataFrame(X_data_series)\n",
    "#     X_data_DF = X_data_series\n",
    "    regexes = [\n",
    "      re.compile(r'\\b(I|we)\\b.*\\b(am|are|will be)\\b.*\\b(bringing|giving|helping|raising|donating|auctioning)\\b', re.I|re.M),\n",
    "      re.compile(r'\\b(I\\'m)\\b.*\\b(bringing|giving|helping|raising|donating|auctioning)\\b', re.I|re.M),\n",
    "      re.compile(r'\\b(we\\'re)\\b.*\\b(bringing|giving|helping|raising|donating|auctioning)\\b', re.I|re.M),\n",
    "      re.compile(r'\\b(I|we)\\b.*\\b(will|would like to)\\b.*\\b(bring|give|help|raise|donate|auction)\\b', re.I|re.M),\n",
    "      re.compile(r'\\b(I|we)\\b.*\\b(will|would like to)\\b.*\\b(work|volunteer|assist)\\b', re.I|re.M),\n",
    "      re.compile(r'\\b(we\\'ll)\\b.*\\b(bring|give|help|raise|donate|auction)\\b', re.I|re.M),\n",
    "      re.compile(r'\\b(I|we)\\b.*\\b(ready|prepared)\\b.*\\b(bring|give|help|raise|donate|auction)\\b', re.I|re.M),\n",
    "      re.compile(r'\\b(where)\\b.*\\b(can I|can we)\\b.*\\b(bring|give|help|raise|donate)\\b', re.I|re.M),\n",
    "      re.compile(r'\\b(where)\\b.*\\b(can I|can we)\\b.*\\b(work|volunteer|assist)\\b', re.I|re.M),\n",
    "      re.compile(r'\\b(I|we)\\b.*\\b(like|want)\\b.*\\bto\\b.*\\b(bring|give|help|raise|donate)\\b', re.I|re.M),\n",
    "      re.compile(r'\\b(I|we)\\b.*\\b(like|want)\\b.*\\bto\\b.*\\b(work|volunteer|assist)\\b', re.I|re.M),\n",
    "      re.compile(r'\\b(will be)\\b.*\\b(brought|given|raised|donated|auctioned)\\b', re.I|re.M),\n",
    "      re.compile(r'\\b\\w*\\s*\\b\\?', re.I|re.M),\n",
    "      re.compile(r'\\b(you|u).*(can|could|should|want to)\\b', re.I|re.M),\n",
    "      re.compile(r'\\b(can|could|should).*(you|u)\\b', re.I|re.M),\n",
    "      re.compile(r'\\b(like|want)\\b.*\\bto\\b.*\\b(bring|give|help|raise|donate)\\b', re.I|re.M),\n",
    "      re.compile(r'\\b(how)\\b.*\\b(can I|can we)\\b.*\\b(bring|give|help|raise|donate)\\b', re.I|re.M),\n",
    "      re.compile(r'\\b(how)\\b.*\\b(can I|can we)\\b.*\\b(work|volunteer|assist)\\b', re.I|re.M)\n",
    "\n",
    "    ]\n",
    "    temp = pd.DataFrame()\n",
    "    features_arg = []\n",
    "    for i, regex in zip(range(len(regexes)), regexes):\n",
    "      columnName = \"RegEx_\" + str(i + 1)\n",
    "      features_arg.append(columnName)\n",
    "      temp[columnName] = X_data_DF['tweet_text'].apply(lambda text: apply_regex(text, regex))\n",
    "    temp_sparse = scipy.sparse.csr_matrix(temp.values)\n",
    "    return temp_sparse, features_arg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "traditional_loadVect() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24466/1774987711.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mpath_to_PreprocessedDataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../datasets/500_random_sample.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraditional_loadVect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathToTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraditional_loadedVecGetFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_PreprocessedDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_nonPreprocessedDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_rules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: traditional_loadVect() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "class UsePretrainedVectClf:\n",
    "    def traditional_loadVect(pathToTokenizer, include_rules=False):\n",
    "        if \"WRul\" in pathToTokenizer:\n",
    "            if include_rules:\n",
    "                print(\"Vectoirzer and appending does not match\")\n",
    "        if \"WoRul\" in pathToTokenizer:\n",
    "            if include_rules:\n",
    "                print(\"Vectoirzer and appending does not match\")\n",
    "        load_vect = pickle.load(open(pathToTokenizer, 'rb'))\n",
    "        return load_vect\n",
    "\n",
    "        # df = pd.read_csv(path_to_PreprocessedDataset)\n",
    "        # X_train_WoR_dtm = load_vect.transform(df[\"tweet_text\"])\n",
    "        # X_train_WoR_Features = list(load_vect.get_feature_names_out())\n",
    "        # if include_rules:\n",
    "        #     X_train_WR_dtm, combined_features = concat_sparse_matrices_h(X_train_WoR_dtm, X_Rules_dtm, X_train_WoR_Features, features_Rules)\n",
    "        #     return X_train_WoR_dtm\n",
    "        # return X_train_WoR_dtm\n",
    "\n",
    "    def traditional_loadedVecGetFeatures(tokenizer, path_to_PreprocessedDataset, path_to_nonPreprocessedDataset, include_rules=False):\n",
    "        df = pd.read_csv(path_to_PreprocessedDataset)\n",
    "        X_train_WoR_dtm = tokenizer.transform(df[\"tweet_text\"])\n",
    "        X_train_WoR_Features = list(tokenizer.get_feature_names_out())\n",
    "        if include_rules:\n",
    "            df_notPreprocessed = pd.read_csv(path_to_nonPreprocessedDataset,  encoding = \"ISO-8859-1\")\n",
    "            X_train_dtm, X_train_Features = apply_gen_rules_features_ngrams(df_notPreprocessed[\"tweet_text\"], X_train_WoR_dtm, X_train_Features)\n",
    "        else:\n",
    "            X_train_dtm = X_train_WoR_dtm\n",
    "        X_train_dtm, indices_uniq = np.unique(X_train_dtm.toarray(), return_index=True, axis=0)\n",
    "        return X_train_dtm, indices_uniq, Vect\n",
    "# def traditional_loadClf\n",
    "\n",
    "obj = UsePretrainedVectClf()\n",
    "vect_filename = \"22-05-06_20-59-32_Unigrams_CountVect_WRul_Freq-3803\"\n",
    "pathToTokenizer= \"../simple_vect/\" + vect_filename\n",
    "\n",
    "clfModel_filename = \"22-05-06_20-59-32_Unigrams_CountVect_WRul_Freq-3803\"\n",
    "pathToClfModel = \"../simple_vect/\" + clfModel_filename\n",
    "\n",
    "path_to_nonPreprocessedDataset = \"../datasets/500_random_sample.csv\"\n",
    "path_to_PreprocessedDataset = \"../datasets/500_random_sample.csv\"\n",
    "\n",
    "tokenizer = obj.traditional_loadVect(pathToTokenizer, include_rules=False)\n",
    "\n",
    "X = obj.traditional_loadedVecGetFeatures(tokenizer, path_to_PreprocessedDataset, path_to_nonPreprocessedDataset, include_rules = False)\n",
    "print(X.shape)\n",
    "# fnameTrainingDataset = \"../datasets/500_random_sample.csv\"\n",
    "# df = pd.read_csv(fnameTrainingDataset)\n",
    "# X = df['tweet_text']\n",
    "# y_binary = df['tweet_class']\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# y_binary = le.fit_transform(y_binary)\n",
    "\n",
    "# classes_labels_binary = le.classes_\n",
    "# X_train_WoR_dtm = load_vect.transform(X)\n",
    "# X_train_WoR_Features = list(load_vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Rules_dtm, features_Rules = gen_rules_features(X)\n",
    "X_train_WR_dtm, combined_features = concat_sparse_matrices_h(X_train_WoR_dtm, X_Rules_dtm, X_train_WoR_Features, features_Rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"22-05-06_20-59-32_CountVect_WRul_Freq-3803_22-05-06_20-59-32_Unigrams_CountVect_WRul_Freq-3803_DT\"\n",
    "path = \"../simple_clfModels//\" + filename\n",
    "\n",
    "load_model = pickle.load(open(path, 'rb'))\n",
    "y_bin_pred = load_model.predict(X_train_WR_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['DT'] = y_bin_pred.tolist()\n",
    "df['GB'] = np.random.randint(2, size=500).tolist()\n",
    "df['MLP'] = np.random.randint(2, size=500).tolist()\n",
    "df['RF'] = np.random.randint(2, size=500).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"request\"] = df.iloc[:, -4:].mean(axis=1) > 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>GB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DT  GB  MLP  RF\n",
       "0     0   0    1   0\n",
       "1     1   0    1   1\n",
       "2     0   1    1   1\n",
       "3     0   1    1   1\n",
       "4     0   1    0   0\n",
       "..   ..  ..  ...  ..\n",
       "495   1   0    0   1\n",
       "496   0   0    1   1\n",
       "497   0   0    1   1\n",
       "498   0   1    0   1\n",
       "499   0   0    0   1\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, -4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "e = np.empty([0])\n",
    "e = np.append(e, 1)\n",
    "e = np.append(e, 2)\n",
    "e = np.append(e, 3)\n",
    "print(list(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [2, 2],\n",
       "       [3, 0],\n",
       "       [0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, -2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>RF</th>\n",
       "      <th>num_uniq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GB  MLP  RF  num_uniq\n",
       "0     0    1   1         4\n",
       "1     0    0   0         4\n",
       "2     0    0   0         4\n",
       "3     1    1   0         4\n",
       "4     1    1   1         4\n",
       "..   ..  ...  ..       ...\n",
       "495   0    0   0         4\n",
       "496   1    0   1         4\n",
       "497   0    0   0         4\n",
       "498   0    0   0         4\n",
       "499   0    0   1         4\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, -:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "[1. 2. 3. 0.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1  c2  c3  c4  new\n",
       "0   1   1   1   0  1.0\n",
       "1   2   1   2   2  2.0\n",
       "2   2   3   3   0  3.0\n",
       "3   2   0   0   0  0.0"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_max_from_rows_into_column(df, indexes):\n",
    "    \"\"\" The function takes dataframe and index of columns, and \n",
    "    then it returns the array containg the most frequent value against each row.\n",
    "    Example: \n",
    "    dataframe:\n",
    "    'c1' | 'c2'| 'c3' | 'c4'\n",
    "    -------------------------\n",
    "      1  |  1  |   1  |  0  \n",
    "      2  |  1  |   2  |  2\n",
    "      2  |  3  |   3  |  0 \n",
    "      2  |  0  |   0  |  0 \n",
    "      returned array:\n",
    "      (1, 2, 3, 0)\n",
    "      df: dataframe\n",
    "      indexes: indexes of columns\n",
    "      example: get_max_from_rows_into_column(dataframe, -3:)\n",
    "      \"\"\"\n",
    "    def get_array(df):\n",
    "        max_unique_label_column = np.empty([0])\n",
    "        for v in df.values:\n",
    "            unique_label, freq_label = np.unique(v, return_counts=True)\n",
    "            print(unique_label[np.argmax(freq_label)])\n",
    "            max_unique_label_column = np.append(max_unique_label_column, unique_label[np.argmax(freq_label)])\n",
    "            \n",
    "#             print(unique_label[np.argmax(freq_label)])\n",
    "        return max_unique_label_column\n",
    "    if \":\" in indexes:\n",
    "        if indexes[0] == \":\":\n",
    "            \n",
    "            df = df.iloc[:, :int(indexes[1:])]\n",
    "            max_unique_label_column = get_array(df)\n",
    "        if indexes[-1] == \":\":\n",
    "            df = df.iloc[:, int(indexes[:-1]):]\n",
    "            max_unique_label_column = get_array(df)\n",
    "           \n",
    "        else:\n",
    "            indexes = [int(x) for x in indexes.split(\":\")]\n",
    "            df = df.iloc[:, indexes[0]: indexes[1]]\n",
    "            max_unique_label_column = get_array(df)\n",
    "    else:\n",
    "            indexes = [int(x) for x in indexes.split(\",\")]\n",
    "            df = df.iloc[:, indexes]\n",
    "            max_unique_label_column = get_array(df)\n",
    "    print(max_unique_label_column)\n",
    "    return max_unique_label_column\n",
    "#     for v in df.iloc[:, indexes].values:\n",
    "#         unique_label, freq_label = np.unique(v, return_counts=True)\n",
    "#         print(unique_label)\n",
    "#         print(freq_label)\n",
    "#         print(unique_label[np.argmax(freq_label)])\n",
    "#     #     print(counts.indexOf(max(counts)))\n",
    "    #     print(unique)\n",
    "\n",
    "#         print(40*\"*\")\n",
    "\n",
    "d = {'c1': [1, 2, 2, 2], 'c2': [1, 1, 3, 0], 'c3': [1, 2, 3, 0], 'c4': [0, 2, 0, 0]}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "indexes = \"-3:\"\n",
    "df[\"new\"] = get_max_from_rows_into_column(df, indexes)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4:-3\n",
      "[-4, -3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>GB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DT  GB\n",
       "0     0   0\n",
       "1     1   0\n",
       "2     0   1\n",
       "3     0   1\n",
       "4     0   1\n",
       "..   ..  ..\n",
       "495   1   0\n",
       "496   0   0\n",
       "497   0   0\n",
       "498   0   1\n",
       "499   0   0\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = \"-4:-3\"\n",
    "print(indexes)\n",
    "if \":\" in indexes:\n",
    "    if indexes[0] == \":\" or indexes[-1] == \":\":\n",
    "        indexes = indexes\n",
    "    else:\n",
    "        indexes = [int(x) for x in indexes.split(\":\")]\n",
    "        return\n",
    "else:\n",
    "    indexes = [int(x) for x in indexes.split(\",\")]\n",
    "print(indexes)\n",
    "df.iloc[:, indexes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1  c2  c3  c4\n",
       "0   1   1   1   0\n",
       "1   2   1   2   0\n",
       "2   2   3   2   0\n",
       "3   2   0   0   0"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'c1': [1, 2, 2, 2], 'c2': [1, 1, 3, 0], 'c3': [1, 2, 2, 0], 'c4': [0, 2, 0, 0]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-299-fb0fb3b0f8c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-299-fb0fb3b0f8c9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "[int(x) for x in indexes.split(\":\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-433'"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = \":-433\"\n",
    "indexes[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "495    1\n",
       "496    0\n",
       "497    0\n",
       "498    0\n",
       "499    0\n",
       "Name: DT, Length: 500, dtype: int64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, -4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>GB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DT  GB  MLP  RF\n",
       "0     0   0    1   0\n",
       "1     1   0    1   1\n",
       "2     0   1    1   1\n",
       "3     0   1    1   1\n",
       "4     0   1    0   0\n",
       "..   ..  ..  ...  ..\n",
       "495   1   0    0   1\n",
       "496   0   0    1   1\n",
       "497   0   0    1   1\n",
       "498   0   1    0   1\n",
       "499   0   0    0   1\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, -4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_uniq'] = [len(set(v[pd.notna(v)].tolist())) for v in df.iloc[:, -4:].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_uniq'] = df.iloc[:, -4:].stack().groupby(level=0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      4\n",
       "1      4\n",
       "2      4\n",
       "3      4\n",
       "4      4\n",
       "      ..\n",
       "495    4\n",
       "496    4\n",
       "497    4\n",
       "498    4\n",
       "499    4\n",
       "Name: num_uniq, Length: 500, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(array, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([11, 12, 13, 14, 15, 16, 17, 15, 11, 12, 14, 15, 16, 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 12, 13, 14, 15, 16, 17, 15, 11, 12, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[np.argmax(arr)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virEnv375",
   "language": "python",
   "name": "virenv375"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 23:27:51.246067: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import re\n",
    "import scipy\n",
    "import numpy as np\n",
    "import glob\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"22-04-02_23-10-18_doc2vec_Vect_WoRul_Max-Len-Seq-20_Freq-20_CNN\"\n",
    "path = \"F:/RweetMiner/RweetMinerNew/request_identification_class_DLCorrected/doc2vec_clfModels/\" + filename\n",
    "load_model = pickle.load(open(path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UsePretrainedVectClf:\n",
    "    def __init__(self, pathToTokenizer, pathToClfModel, path_to_PreprocessedDataset, path_to_nonPreprocessedDataset, include_rules = False):\n",
    "        self.path_to_nonPreprocessedDataset = path_to_nonPreprocessedDataset\n",
    "        self.path_to_PreprocessedDataset = path_to_PreprocessedDataset\n",
    "        self.include_rules = include_rules\n",
    "        self.pathToTokenizer = pathToTokenizer\n",
    "        self.pathToClfModel = pathToClfModel\n",
    "    \n",
    "    def traditional_ChangeVectPath(self, pathToTokenizer):\n",
    "        self.pathToTokenizer = pathToTokenizer   \n",
    "        \n",
    "    def traditional_loadClf(self):  \n",
    "        clf_model = pickle.load(open(self.pathToClfModel, 'rb'))\n",
    "        return clf_model\n",
    "    \n",
    "    def traditional_ChangeClfModelPath(self, pathToClfModel):\n",
    "        self.pathToClfModel = pathToClfModel     \n",
    "        \n",
    "    def traditional_loadVect(self):\n",
    "        Vect = pickle.load(open(self.pathToTokenizer, 'rb'))\n",
    "        return Vect\n",
    "    \n",
    "    def apply_gen_rules_features_ngrams(self, X, X_train_WoR_dtm, X_train_WoR_Features):\n",
    "        X_Rules_dtm, features_Rules = self.gen_rules_features_ngrams(X)\n",
    "        X_train_WR_dtm, combined_features = self.concat_sparse_matrices_h(X_train_WoR_dtm, X_Rules_dtm,\n",
    "                                                                          X_train_WoR_Features, features_Rules)\n",
    "        return X_train_WR_dtm, combined_features\n",
    "\n",
    "\n",
    "    def gen_rules_features_ngrams(self, X_data_series):  # , X_data_dtm, features_arg):\n",
    "        '''sparse matrix and series matrices should be converted to dataframe for applying rules and treating\n",
    "        it as features...\n",
    "        I wrote two functions i.e.,sparse_matrix_to_DataFrame() and series_DataFrame()\n",
    "          for changing datatypes'''\n",
    "        \n",
    "        X_data_DF = self.series_to_DataFrame(X_data_series)\n",
    "        regexes = [\n",
    "            re.compile(r'\\b(I|we)\\b.*\\b(am|are|will be)\\b.*\\b(bringing|giving|helping|raising|donating|auctioning)\\b',\n",
    "                       re.I | re.M),\n",
    "            re.compile(r'\\b(I\\'m)\\b.*\\b(bringing|giving|helping|raising|donating|auctioning)\\b', re.I | re.M),\n",
    "            re.compile(r'\\b(we\\'re)\\b.*\\b(bringing|giving|helping|raising|donating|auctioning)\\b', re.I | re.M),\n",
    "            re.compile(r'\\b(I|we)\\b.*\\b(will|would like to)\\b.*\\b(bring|give|help|raise|donate|auction)\\b',\n",
    "                       re.I | re.M),\n",
    "            re.compile(r'\\b(I|we)\\b.*\\b(will|would like to)\\b.*\\b(work|volunteer|assist)\\b', re.I | re.M),\n",
    "            re.compile(r'\\b(we\\'ll)\\b.*\\b(bring|give|help|raise|donate|auction)\\b', re.I | re.M),\n",
    "            re.compile(r'\\b(I|we)\\b.*\\b(ready|prepared)\\b.*\\b(bring|give|help|raise|donate|auction)\\b', re.I | re.M),\n",
    "            re.compile(r'\\b(where)\\b.*\\b(can I|can we)\\b.*\\b(bring|give|help|raise|donate)\\b', re.I | re.M),\n",
    "            re.compile(r'\\b(where)\\b.*\\b(can I|can we)\\b.*\\b(work|volunteer|assist)\\b', re.I | re.M),\n",
    "            re.compile(r'\\b(I|we)\\b.*\\b(like|want)\\b.*\\bto\\b.*\\b(bring|give|help|raise|donate)\\b', re.I | re.M),\n",
    "            re.compile(r'\\b(I|we)\\b.*\\b(like|want)\\b.*\\bto\\b.*\\b(work|volunteer|assist)\\b', re.I | re.M),\n",
    "            re.compile(r'\\b(will be)\\b.*\\b(brought|given|raised|donated|auctioned)\\b', re.I | re.M),\n",
    "            re.compile(r'\\b\\w*\\s*\\b\\?', re.I | re.M),\n",
    "            re.compile(r'\\b(you|u).*(can|could|should|want to)\\b', re.I | re.M),\n",
    "            re.compile(r'\\b(can|could|should).*(you|u)\\b', re.I | re.M),\n",
    "            re.compile(r'\\b(like|want)\\b.*\\bto\\b.*\\b(bring|give|help|raise|donate)\\b', re.I | re.M),\n",
    "            re.compile(r'\\b(how)\\b.*\\b(can I|can we)\\b.*\\b(bring|give|help|raise|donate)\\b', re.I | re.M),\n",
    "            re.compile(r'\\b(how)\\b.*\\b(can I|can we)\\b.*\\b(work|volunteer|assist)\\b', re.I | re.M)\n",
    "\n",
    "        ]\n",
    "        temp = pd.DataFrame()\n",
    "        features_arg = []\n",
    "        for i, regex in zip(range(len(regexes)), regexes):\n",
    "            columnName = \"RegEx_\" + str(i + 1)\n",
    "            features_arg.append(columnName)\n",
    "            temp[columnName] = X_data_DF['tweet_text'].apply(lambda text: self.apply_regex_ngrams(text, regex))\n",
    "        temp_sparse = scipy.sparse.csr_matrix(temp.values)\n",
    "        return temp_sparse, features_arg\n",
    "    \n",
    "    def series_to_DataFrame(self, X_data):\n",
    "        X_data = X_data.to_frame()\n",
    "        return X_data\n",
    "    \n",
    "    def concat_sparse_matrices_h(self, data_X_dtm, data_Rules_dtm, features_X, features_Rules):\n",
    "        combined_features = features_X + features_Rules\n",
    "        concat_sparse = scipy.sparse.hstack([data_X_dtm, data_Rules_dtm], format='csr')\n",
    "        return concat_sparse, combined_features\n",
    "    \n",
    "    def apply_regex_ngrams(self, text, regex):\n",
    "        match_found = (re.search(regex, text) != None)\n",
    "        match_found = int(match_found == True)\n",
    "        return match_found\n",
    "    \n",
    "    def traditional_getFeatures(self, Vect):\n",
    "        df = pd.read_csv(self.path_to_PreprocessedDataset, encoding = \"ISO-8859-1\")\n",
    "        X_train_WoR_dtm = Vect.transform(df[\"tweet_text\"])\n",
    "        X_train_Features = list(Vect.get_feature_names_out())\n",
    "        if self.include_rules:\n",
    "            df_notPreprocessed = pd.read_csv(self.path_to_nonPreprocessedDataset,  encoding = \"ISO-8859-1\")\n",
    "            X_train_dtm, X_train_Features = self.apply_gen_rules_features_ngrams(df_notPreprocessed[\"tweet_text\"], \\\n",
    "                                                                      X_train_WoR_dtm, X_train_Features)\n",
    "        else:\n",
    "            X_train_dtm = X_train_WoR_dtm\n",
    "        return X_train_dtm.toarray(), Vect\n",
    "\n",
    "\n",
    "    \n",
    "    def get_predictions(self, clf_model, X):\n",
    "        return clf_model.predict(X)\n",
    "        \n",
    "    \n",
    "    def evaluation(self):\n",
    "        if \"WRul\" in self.pathToTokenizer:\n",
    "            if not self.include_rules:\n",
    "                print(\"Vectoirzer and appending does not match\")\n",
    "        if \"WoRul\" in self.pathToTokenizer:\n",
    "            if self.include_rules:\n",
    "                print(\"Vectoirzer and appending does not match\")\n",
    "        if \"WRul\" in self.pathToClfModel:\n",
    "            if not self.include_rules:\n",
    "                print(\"Vectoirzer and appending does not match\")\n",
    "        if \"WoRul\" in self.pathToClfModel:\n",
    "            if self.include_rules:\n",
    "                print(\"Vectoirzer and appending does not match\")\n",
    "        if not self.pathToClfModel.split(\"/\")[-1].split(\"_\")[5:-1] == self.pathToTokenizer.split(\"/\")[-1].split(\"_\"):\n",
    "            print(\"Vectorizer and classifer does not match.\")\n",
    "            print(\"Vectorizer:\", self.pathToTokenizer)\n",
    "            print(\"Classifier:\", self.pathToClfModel)\n",
    "            print(\"Classifier:\", self.pathToTokenizer.split(\"/\")[-1].split(\"_\"), \"Vectorizer:\" , self.pathToClfModel.split(\"/\")[-1].split(\"_\")[5:-1])\n",
    "def generateNameFromDataSetName(list1):\n",
    "    str1 = \"\"\n",
    "    for e in list1:\n",
    "        if e == \"\":\n",
    "            str1 += '.'.join(str(e))\n",
    "        else:\n",
    "            if e == \"csv\":\n",
    "                e = \"_withPredictions.\" + e\n",
    "                str1 += ''.join(str(e))\n",
    "            else:\n",
    "                str1 += ''.join(str(e))\n",
    "    return \"..\" + str1\n",
    "  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Unigrams_WRul_CountVect_Freq-3803_DT\n",
      "Unigrams_WRul_CountVect_Freq-3803_GB\n",
      "Unigrams_WRul_CountVect_Freq-3803_LR\n",
      "Unigrams_WRul_CountVect_Freq-3803_MLP\n",
      "Unigrams_WRul_CountVect_Freq-3803_NB\n",
      "Unigrams_WRul_CountVect_Freq-3803_RF\n",
      "Unigrams_WRul_CountVect_Freq-3803_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "UniAndBigrams_WRul_CountVect_Freq-16176_DT\n",
      "UniAndBigrams_WRul_CountVect_Freq-16176_GB\n",
      "UniAndBigrams_WRul_CountVect_Freq-16176_LR\n",
      "UniAndBigrams_WRul_CountVect_Freq-16176_MLP\n",
      "UniAndBigrams_WRul_CountVect_Freq-16176_NB\n",
      "UniAndBigrams_WRul_CountVect_Freq-16176_RF\n",
      "UniAndBigrams_WRul_CountVect_Freq-16176_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "UniBiAndTrigrams_WRul_CountVect_Freq-32026_DT\n",
      "UniBiAndTrigrams_WRul_CountVect_Freq-32026_GB\n",
      "UniBiAndTrigrams_WRul_CountVect_Freq-32026_LR\n",
      "UniBiAndTrigrams_WRul_CountVect_Freq-32026_MLP\n",
      "UniBiAndTrigrams_WRul_CountVect_Freq-32026_NB\n",
      "UniBiAndTrigrams_WRul_CountVect_Freq-32026_RF\n",
      "UniBiAndTrigrams_WRul_CountVect_Freq-32026_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Bigrams_WRul_CountVect_Freq-12391_DT\n",
      "Bigrams_WRul_CountVect_Freq-12391_GB\n",
      "Bigrams_WRul_CountVect_Freq-12391_LR\n",
      "Bigrams_WRul_CountVect_Freq-12391_MLP\n",
      "Bigrams_WRul_CountVect_Freq-12391_NB\n",
      "Bigrams_WRul_CountVect_Freq-12391_RF\n",
      "Bigrams_WRul_CountVect_Freq-12391_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "BiTrigrams_WRul_CountVect_Freq-28241_DT\n",
      "BiTrigrams_WRul_CountVect_Freq-28241_GB\n",
      "BiTrigrams_WRul_CountVect_Freq-28241_LR\n",
      "BiTrigrams_WRul_CountVect_Freq-28241_MLP\n",
      "BiTrigrams_WRul_CountVect_Freq-28241_NB\n",
      "BiTrigrams_WRul_CountVect_Freq-28241_RF\n",
      "BiTrigrams_WRul_CountVect_Freq-28241_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Trigrams_WRul_CountVect_Freq-15868_GB\n",
      "Trigrams_WRul_CountVect_Freq-15868_DT\n",
      "Trigrams_WRul_CountVect_Freq-15868_LR\n",
      "Trigrams_WRul_CountVect_Freq-15868_MLP\n",
      "Trigrams_WRul_CountVect_Freq-15868_NB\n",
      "Trigrams_WRul_CountVect_Freq-15868_RF\n",
      "Trigrams_WRul_CountVect_Freq-15868_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Unigrams_WoRul_CountVect_Freq-3785_LR\n",
      "Unigrams_WoRul_CountVect_Freq-3785_DT\n",
      "Unigrams_WoRul_CountVect_Freq-3785_GB\n",
      "Unigrams_WoRul_CountVect_Freq-3785_MLP\n",
      "Unigrams_WoRul_CountVect_Freq-3785_NB\n",
      "Unigrams_WoRul_CountVect_Freq-3785_RF\n",
      "Unigrams_WoRul_CountVect_Freq-3785_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "UniAndBigrams_WoRul_CountVect_Freq-16158_LR\n",
      "UniAndBigrams_WoRul_CountVect_Freq-16158_DT\n",
      "UniAndBigrams_WoRul_CountVect_Freq-16158_GB\n",
      "UniAndBigrams_WoRul_CountVect_Freq-16158_MLP\n",
      "UniAndBigrams_WoRul_CountVect_Freq-16158_NB\n",
      "UniAndBigrams_WoRul_CountVect_Freq-16158_RF\n",
      "UniAndBigrams_WoRul_CountVect_Freq-16158_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "UniBiAndTrigrams_WoRul_CountVect_Freq-32008_LR\n",
      "UniBiAndTrigrams_WoRul_CountVect_Freq-32008_DT\n",
      "UniBiAndTrigrams_WoRul_CountVect_Freq-32008_GB\n",
      "UniBiAndTrigrams_WoRul_CountVect_Freq-32008_MLP\n",
      "UniBiAndTrigrams_WoRul_CountVect_Freq-32008_NB\n",
      "UniBiAndTrigrams_WoRul_CountVect_Freq-32008_RF\n",
      "UniBiAndTrigrams_WoRul_CountVect_Freq-32008_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Bigrams_WoRul_CountVect_Freq-12373_LR\n",
      "Bigrams_WoRul_CountVect_Freq-12373_DT\n",
      "Bigrams_WoRul_CountVect_Freq-12373_GB\n",
      "Bigrams_WoRul_CountVect_Freq-12373_MLP\n",
      "Bigrams_WoRul_CountVect_Freq-12373_NB\n",
      "Bigrams_WoRul_CountVect_Freq-12373_RF\n",
      "Bigrams_WoRul_CountVect_Freq-12373_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "BiTrigrams_WoRul_CountVect_Freq-28223_LR\n",
      "BiTrigrams_WoRul_CountVect_Freq-28223_DT\n",
      "BiTrigrams_WoRul_CountVect_Freq-28223_GB\n",
      "BiTrigrams_WoRul_CountVect_Freq-28223_MLP\n",
      "BiTrigrams_WoRul_CountVect_Freq-28223_NB\n",
      "BiTrigrams_WoRul_CountVect_Freq-28223_RF\n",
      "BiTrigrams_WoRul_CountVect_Freq-28223_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Trigrams_WoRul_CountVect_Freq-15850_DT\n",
      "Trigrams_WoRul_CountVect_Freq-15850_GB\n",
      "Trigrams_WoRul_CountVect_Freq-15850_LR\n",
      "Trigrams_WoRul_CountVect_Freq-15850_MLP\n",
      "Trigrams_WoRul_CountVect_Freq-15850_NB\n",
      "Trigrams_WoRul_CountVect_Freq-15850_RF\n",
      "Trigrams_WoRul_CountVect_Freq-15850_SVM\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# # vect_filename = \"22-05-06_20-59-32_Unigrams_CountVect_WRul_Freq-3803\"\n",
    "\n",
    "\n",
    "\n",
    "# pathToTokenizer= \"\" \n",
    "\n",
    "# # clfModel_filename = \"22-05-06_20-59-32_CountVect_WRul_Freq-3803_22-05-06_20-59-32_Unigrams_CountVect_WRul_Freq-3803_DT\"\n",
    "# # clfModel_filename = \"\"\n",
    "\n",
    "pathToClfModel = \"\" \n",
    "path_to_nonPreprocessedDataset = \"../datasets/500_random_sample.csv\"\n",
    "path_to_PreprocessedDataset = \"../datasets/500_random_sample_processed.csv\"\n",
    "pathToVectFolder = \"../simple_vect/\"\n",
    "pathToClfFolder = \"../simple_clfModels/\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "obj = UsePretrainedVectClf(pathToVectFolder, pathToClfModel, path_to_PreprocessedDataset, path_to_nonPreprocessedDataset, include_rules = False)\n",
    "NotProcessedDataWithPredictions = pd.read_csv(obj.path_to_nonPreprocessedDataset, encoding = \"ISO-8859-1\")\n",
    "ProcessedDataWithPredictions = pd.read_csv(obj.path_to_PreprocessedDataset, encoding = \"ISO-8859-1\")\n",
    "# print(NotProcessedDataWithPredictions.shape, ProcessedDataWithPredictions.shape)\n",
    "for vect_filename in glob.glob(pathToVectFolder + \"/*\"):\n",
    "    print(40*\"+\")\n",
    "    obj.traditional_ChangeVectPath(vect_filename)\n",
    "    Vect = obj.traditional_loadVect()\n",
    "    for clfModel_filename in glob.glob(pathToClfFolder + \"*\"):\n",
    "        if clfModel_filename.split(\"/\")[-1].split(\"_\")[5:-1] == vect_filename.split(\"/\")[-1].split(\"_\"):\n",
    "            obj.traditional_ChangeClfModelPath(clfModel_filename)\n",
    "            name_cell = obj.pathToClfModel.split(\"/\")[-1].split(\"_\")[5:]\n",
    "            if name_cell[-3] == \"WRul\":\n",
    "                obj.include_rules = True\n",
    "            else:\n",
    "                obj.include_rules = False\n",
    "            # print(obj.pathToTokenizer, obj.pathToClfModel)\n",
    "            # print(name_cell)\n",
    "            # print(name_cell[-5] + \"_\" + name_cell[-3]  + \"_\" + name_cell[-4] + \"_\" + name_cell[-2] + \"_\" + name_cell[-1])\n",
    "            X, _ = obj.traditional_getFeatures(Vect)\n",
    "            clf_model = obj.traditional_loadClf()\n",
    "            y_pred = obj.get_predictions(clf_model, X)\n",
    "            name_cell = name_cell[-5] + \"_\" + name_cell[-3]  + \"_\" + name_cell[-4] + \"_\" + name_cell[-2] + \"_\" + name_cell[-1]\n",
    "            print(name_cell)\n",
    "            NotProcessedDataWithPredictions[name_cell] = y_pred.tolist()\n",
    "            ProcessedDataWithPredictions[name_cell] = y_pred.tolist()\n",
    "     \n",
    "                 \n",
    "\n",
    "notProcessedDatasetName = generateNameFromDataSetName(obj.path_to_nonPreprocessedDataset.split(\".\"))\n",
    "NotProcessedDataWithPredictions.to_csv(notProcessedDatasetName)\n",
    "# processedDatasetName = generateNameFromDataSetName(obj.path_to_PreprocessedDataset.split(\".\"))\n",
    "# ProcessedDataWithPredictions.to_csv(processedDatasetName)\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Unigrams_WoRul_TfIdfVect_Freq-3785_DT\n",
      "Unigrams_WoRul_TfIdfVect_Freq-3785_GB\n",
      "Unigrams_WoRul_TfIdfVect_Freq-3785_LR\n",
      "Unigrams_WoRul_TfIdfVect_Freq-3785_MLP\n",
      "Unigrams_WoRul_TfIdfVect_Freq-3785_NB\n",
      "Unigrams_WoRul_TfIdfVect_Freq-3785_RF\n",
      "Unigrams_WoRul_TfIdfVect_Freq-3785_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "UniAndBigrams_WoRul_TfIdfVect_Freq-16158_DT\n",
      "UniAndBigrams_WoRul_TfIdfVect_Freq-16158_GB\n",
      "UniAndBigrams_WoRul_TfIdfVect_Freq-16158_LR\n",
      "UniAndBigrams_WoRul_TfIdfVect_Freq-16158_MLP\n",
      "UniAndBigrams_WoRul_TfIdfVect_Freq-16158_NB\n",
      "UniAndBigrams_WoRul_TfIdfVect_Freq-16158_RF\n",
      "UniAndBigrams_WoRul_TfIdfVect_Freq-16158_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "UniBiAndTrigrams_WoRul_TfIdfVect_Freq-32008_DT\n",
      "UniBiAndTrigrams_WoRul_TfIdfVect_Freq-32008_GB\n",
      "UniBiAndTrigrams_WoRul_TfIdfVect_Freq-32008_LR\n",
      "UniBiAndTrigrams_WoRul_TfIdfVect_Freq-32008_MLP\n",
      "UniBiAndTrigrams_WoRul_TfIdfVect_Freq-32008_NB\n",
      "UniBiAndTrigrams_WoRul_TfIdfVect_Freq-32008_RF\n",
      "UniBiAndTrigrams_WoRul_TfIdfVect_Freq-32008_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Bigrams_WoRul_TfIdfVect_Freq-12373_DT\n",
      "Bigrams_WoRul_TfIdfVect_Freq-12373_GB\n",
      "Bigrams_WoRul_TfIdfVect_Freq-12373_LR\n",
      "Bigrams_WoRul_TfIdfVect_Freq-12373_MLP\n",
      "Bigrams_WoRul_TfIdfVect_Freq-12373_NB\n",
      "Bigrams_WoRul_TfIdfVect_Freq-12373_RF\n",
      "Bigrams_WoRul_TfIdfVect_Freq-12373_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "BiTrigrams_WoRul_TfIdfVect_Freq-28223_SVM\n",
      "BiTrigrams_WoRul_TfIdfVect_Freq-28223_DT\n",
      "BiTrigrams_WoRul_TfIdfVect_Freq-28223_GB\n",
      "BiTrigrams_WoRul_TfIdfVect_Freq-28223_LR\n",
      "BiTrigrams_WoRul_TfIdfVect_Freq-28223_MLP\n",
      "BiTrigrams_WoRul_TfIdfVect_Freq-28223_NB\n",
      "BiTrigrams_WoRul_TfIdfVect_Freq-28223_RF\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Trigrams_WoRul_TfIdfVect_Freq-15850_DT\n",
      "Trigrams_WoRul_TfIdfVect_Freq-15850_GB\n",
      "Trigrams_WoRul_TfIdfVect_Freq-15850_LR\n",
      "Trigrams_WoRul_TfIdfVect_Freq-15850_MLP\n",
      "Trigrams_WoRul_TfIdfVect_Freq-15850_NB\n",
      "Trigrams_WoRul_TfIdfVect_Freq-15850_RF\n",
      "Trigrams_WoRul_TfIdfVect_Freq-15850_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Unigrams_WRul_TfIdfVect_Freq-3803_DT\n",
      "Unigrams_WRul_TfIdfVect_Freq-3803_GB\n",
      "Unigrams_WRul_TfIdfVect_Freq-3803_LR\n",
      "Unigrams_WRul_TfIdfVect_Freq-3803_MLP\n",
      "Unigrams_WRul_TfIdfVect_Freq-3803_NB\n",
      "Unigrams_WRul_TfIdfVect_Freq-3803_RF\n",
      "Unigrams_WRul_TfIdfVect_Freq-3803_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "UniAndBigrams_WRul_TfIdfVect_Freq-16176_DT\n",
      "UniAndBigrams_WRul_TfIdfVect_Freq-16176_GB\n",
      "UniAndBigrams_WRul_TfIdfVect_Freq-16176_LR\n",
      "UniAndBigrams_WRul_TfIdfVect_Freq-16176_MLP\n",
      "UniAndBigrams_WRul_TfIdfVect_Freq-16176_NB\n",
      "UniAndBigrams_WRul_TfIdfVect_Freq-16176_RF\n",
      "UniAndBigrams_WRul_TfIdfVect_Freq-16176_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "UniBiAndTrigrams_WRul_TfIdfVect_Freq-32026_DT\n",
      "UniBiAndTrigrams_WRul_TfIdfVect_Freq-32026_GB\n",
      "UniBiAndTrigrams_WRul_TfIdfVect_Freq-32026_LR\n",
      "UniBiAndTrigrams_WRul_TfIdfVect_Freq-32026_MLP\n",
      "UniBiAndTrigrams_WRul_TfIdfVect_Freq-32026_NB\n",
      "UniBiAndTrigrams_WRul_TfIdfVect_Freq-32026_RF\n",
      "UniBiAndTrigrams_WRul_TfIdfVect_Freq-32026_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Bigrams_WRul_TfIdfVect_Freq-12391_DT\n",
      "Bigrams_WRul_TfIdfVect_Freq-12391_GB\n",
      "Bigrams_WRul_TfIdfVect_Freq-12391_LR\n",
      "Bigrams_WRul_TfIdfVect_Freq-12391_MLP\n",
      "Bigrams_WRul_TfIdfVect_Freq-12391_NB\n",
      "Bigrams_WRul_TfIdfVect_Freq-12391_RF\n",
      "Bigrams_WRul_TfIdfVect_Freq-12391_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "BiTrigrams_WRul_TfIdfVect_Freq-28241_GB\n",
      "BiTrigrams_WRul_TfIdfVect_Freq-28241_DT\n",
      "BiTrigrams_WRul_TfIdfVect_Freq-28241_LR\n",
      "BiTrigrams_WRul_TfIdfVect_Freq-28241_MLP\n",
      "BiTrigrams_WRul_TfIdfVect_Freq-28241_NB\n",
      "BiTrigrams_WRul_TfIdfVect_Freq-28241_RF\n",
      "BiTrigrams_WRul_TfIdfVect_Freq-28241_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Trigrams_WRul_TfIdfVect_Freq-15868_DT\n",
      "Trigrams_WRul_TfIdfVect_Freq-15868_GB\n",
      "Trigrams_WRul_TfIdfVect_Freq-15868_LR\n",
      "Trigrams_WRul_TfIdfVect_Freq-15868_MLP\n",
      "Trigrams_WRul_TfIdfVect_Freq-15868_NB\n",
      "Trigrams_WRul_TfIdfVect_Freq-15868_RF\n",
      "Trigrams_WRul_TfIdfVect_Freq-15868_SVM\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "pathToClfModel = \"\" \n",
    "path_to_nonPreprocessedDataset = \"../datasets/500_random_sample_withPredictions.csv\"\n",
    "path_to_PreprocessedDataset = \"../datasets/500_random_sample_processed_withPredictions.csv\"\n",
    "pathToVectFolder = \"../tfidf_vect/\"\n",
    "pathToClfFolder = \"../tfidf_clfModels/\"\n",
    "\n",
    "\n",
    "obj = UsePretrainedVectClf(pathToVectFolder, pathToClfModel, path_to_PreprocessedDataset, path_to_nonPreprocessedDataset, include_rules = False)\n",
    "NotProcessedDataWithPredictions = pd.read_csv(obj.path_to_nonPreprocessedDataset, encoding = \"ISO-8859-1\")\n",
    "ProcessedDataWithPredictions = pd.read_csv(obj.path_to_PreprocessedDataset, encoding = \"ISO-8859-1\")\n",
    "# print(NotProcessedDataWithPredictions.shape, ProcessedDataWithPredictions.shape)\n",
    "for vect_filename in glob.glob(pathToVectFolder + \"/*\"):\n",
    "    print(40*\"+\")\n",
    "    obj.traditional_ChangeVectPath(vect_filename)\n",
    "    Vect = obj.traditional_loadVect()\n",
    "    for clfModel_filename in glob.glob(pathToClfFolder + \"*\"):\n",
    "        if clfModel_filename.split(\"/\")[-1].split(\"_\")[5:-1] == vect_filename.split(\"/\")[-1].split(\"_\"):\n",
    "            obj.traditional_ChangeClfModelPath(clfModel_filename)\n",
    "            name_cell = obj.pathToClfModel.split(\"/\")[-1].split(\"_\")[5:]\n",
    "            if name_cell[-3] == \"WRul\":\n",
    "                obj.include_rules = True\n",
    "            else:\n",
    "                obj.include_rules = False\n",
    "            # print(obj.pathToTokenizer, obj.pathToClfModel)\n",
    "            # print(name_cell)\n",
    "            # print(name_cell[-5] + \"_\" + name_cell[-3]  + \"_\" + name_cell[-4] + \"_\" + name_cell[-2] + \"_\" + name_cell[-1])\n",
    "            X, _ = obj.traditional_getFeatures(Vect)\n",
    "            clf_model = obj.traditional_loadClf()\n",
    "            y_pred = obj.get_predictions(clf_model, X)\n",
    "            name_cell = name_cell[-5] + \"_\" + name_cell[-3]  + \"_\" + name_cell[-4] + \"_\" + name_cell[-2] + \"_\" + name_cell[-1]\n",
    "            print(name_cell)\n",
    "            NotProcessedDataWithPredictions[name_cell] = y_pred.tolist()\n",
    "            ProcessedDataWithPredictions[name_cell] = y_pred.tolist()\n",
    "     \n",
    "                 \n",
    "\n",
    "notProcessedDatasetName = generateNameFromDataSetName(obj.path_to_nonPreprocessedDataset.split(\".\"))\n",
    "NotProcessedDataWithPredictions.to_csv(notProcessedDatasetName)\n",
    "# processedDatasetName = generateNameFromDataSetName(obj.path_to_PreprocessedDataset.split(\".\"))\n",
    "# ProcessedDataWithPredictions.to_csv(processedDatasetName)\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 168)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../datasets/500_random_sample_withPredictions_withPredictions.csv\"\n",
    "df = pd.read_csv(path , encoding = \"ISO-8859-1\")\n",
    "df.iloc[:, 6:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Unigrams_WoRul_TfIdfVect_Freq-3785_DT\n",
      "Unigrams_WoRul_TfIdfVect_Freq-3785_GB\n",
      "Unigrams_WoRul_TfIdfVect_Freq-3785_LR\n",
      "Unigrams_WoRul_TfIdfVect_Freq-3785_MLP\n",
      "Unigrams_WoRul_TfIdfVect_Freq-3785_NB\n",
      "Unigrams_WoRul_TfIdfVect_Freq-3785_RF\n",
      "Unigrams_WoRul_TfIdfVect_Freq-3785_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "UniAndBigrams_WoRul_TfIdfVect_Freq-16158_DT\n",
      "UniAndBigrams_WoRul_TfIdfVect_Freq-16158_GB\n",
      "UniAndBigrams_WoRul_TfIdfVect_Freq-16158_LR\n",
      "UniAndBigrams_WoRul_TfIdfVect_Freq-16158_MLP\n",
      "UniAndBigrams_WoRul_TfIdfVect_Freq-16158_NB\n",
      "UniAndBigrams_WoRul_TfIdfVect_Freq-16158_RF\n",
      "UniAndBigrams_WoRul_TfIdfVect_Freq-16158_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "UniBiAndTrigrams_WoRul_TfIdfVect_Freq-32008_DT\n",
      "UniBiAndTrigrams_WoRul_TfIdfVect_Freq-32008_GB\n",
      "UniBiAndTrigrams_WoRul_TfIdfVect_Freq-32008_LR\n",
      "UniBiAndTrigrams_WoRul_TfIdfVect_Freq-32008_MLP\n",
      "UniBiAndTrigrams_WoRul_TfIdfVect_Freq-32008_NB\n",
      "UniBiAndTrigrams_WoRul_TfIdfVect_Freq-32008_RF\n",
      "UniBiAndTrigrams_WoRul_TfIdfVect_Freq-32008_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Bigrams_WoRul_TfIdfVect_Freq-12373_DT\n",
      "Bigrams_WoRul_TfIdfVect_Freq-12373_GB\n",
      "Bigrams_WoRul_TfIdfVect_Freq-12373_LR\n",
      "Bigrams_WoRul_TfIdfVect_Freq-12373_MLP\n",
      "Bigrams_WoRul_TfIdfVect_Freq-12373_NB\n",
      "Bigrams_WoRul_TfIdfVect_Freq-12373_RF\n",
      "Bigrams_WoRul_TfIdfVect_Freq-12373_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "BiTrigrams_WoRul_TfIdfVect_Freq-28223_SVM\n",
      "BiTrigrams_WoRul_TfIdfVect_Freq-28223_DT\n",
      "BiTrigrams_WoRul_TfIdfVect_Freq-28223_GB\n",
      "BiTrigrams_WoRul_TfIdfVect_Freq-28223_LR\n",
      "BiTrigrams_WoRul_TfIdfVect_Freq-28223_MLP\n",
      "BiTrigrams_WoRul_TfIdfVect_Freq-28223_NB\n",
      "BiTrigrams_WoRul_TfIdfVect_Freq-28223_RF\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Trigrams_WoRul_TfIdfVect_Freq-15850_DT\n",
      "Trigrams_WoRul_TfIdfVect_Freq-15850_GB\n",
      "Trigrams_WoRul_TfIdfVect_Freq-15850_LR\n",
      "Trigrams_WoRul_TfIdfVect_Freq-15850_MLP\n",
      "Trigrams_WoRul_TfIdfVect_Freq-15850_NB\n",
      "Trigrams_WoRul_TfIdfVect_Freq-15850_RF\n",
      "Trigrams_WoRul_TfIdfVect_Freq-15850_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Unigrams_WRul_TfIdfVect_Freq-3803_DT\n",
      "Unigrams_WRul_TfIdfVect_Freq-3803_GB\n",
      "Unigrams_WRul_TfIdfVect_Freq-3803_LR\n",
      "Unigrams_WRul_TfIdfVect_Freq-3803_MLP\n",
      "Unigrams_WRul_TfIdfVect_Freq-3803_NB\n",
      "Unigrams_WRul_TfIdfVect_Freq-3803_RF\n",
      "Unigrams_WRul_TfIdfVect_Freq-3803_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "UniAndBigrams_WRul_TfIdfVect_Freq-16176_DT\n",
      "UniAndBigrams_WRul_TfIdfVect_Freq-16176_GB\n",
      "UniAndBigrams_WRul_TfIdfVect_Freq-16176_LR\n",
      "UniAndBigrams_WRul_TfIdfVect_Freq-16176_MLP\n",
      "UniAndBigrams_WRul_TfIdfVect_Freq-16176_NB\n",
      "UniAndBigrams_WRul_TfIdfVect_Freq-16176_RF\n",
      "UniAndBigrams_WRul_TfIdfVect_Freq-16176_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "UniBiAndTrigrams_WRul_TfIdfVect_Freq-32026_DT\n",
      "UniBiAndTrigrams_WRul_TfIdfVect_Freq-32026_GB\n",
      "UniBiAndTrigrams_WRul_TfIdfVect_Freq-32026_LR\n",
      "UniBiAndTrigrams_WRul_TfIdfVect_Freq-32026_MLP\n",
      "UniBiAndTrigrams_WRul_TfIdfVect_Freq-32026_NB\n",
      "UniBiAndTrigrams_WRul_TfIdfVect_Freq-32026_RF\n",
      "UniBiAndTrigrams_WRul_TfIdfVect_Freq-32026_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Bigrams_WRul_TfIdfVect_Freq-12391_DT\n",
      "Bigrams_WRul_TfIdfVect_Freq-12391_GB\n",
      "Bigrams_WRul_TfIdfVect_Freq-12391_LR\n",
      "Bigrams_WRul_TfIdfVect_Freq-12391_MLP\n",
      "Bigrams_WRul_TfIdfVect_Freq-12391_NB\n",
      "Bigrams_WRul_TfIdfVect_Freq-12391_RF\n",
      "Bigrams_WRul_TfIdfVect_Freq-12391_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "BiTrigrams_WRul_TfIdfVect_Freq-28241_GB\n",
      "BiTrigrams_WRul_TfIdfVect_Freq-28241_DT\n",
      "BiTrigrams_WRul_TfIdfVect_Freq-28241_LR\n",
      "BiTrigrams_WRul_TfIdfVect_Freq-28241_MLP\n",
      "BiTrigrams_WRul_TfIdfVect_Freq-28241_NB\n",
      "BiTrigrams_WRul_TfIdfVect_Freq-28241_RF\n",
      "BiTrigrams_WRul_TfIdfVect_Freq-28241_SVM\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Trigrams_WRul_TfIdfVect_Freq-15868_DT\n",
      "Trigrams_WRul_TfIdfVect_Freq-15868_GB\n",
      "Trigrams_WRul_TfIdfVect_Freq-15868_LR\n",
      "Trigrams_WRul_TfIdfVect_Freq-15868_MLP\n",
      "Trigrams_WRul_TfIdfVect_Freq-15868_NB\n",
      "Trigrams_WRul_TfIdfVect_Freq-15868_RF\n",
      "Trigrams_WRul_TfIdfVect_Freq-15868_SVM\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# import glob\n",
    "\n",
    "\n",
    "\n",
    "# path_to_nonPreprocessedDataset = \"../datasets/500_random_sample (copy).csv\"\n",
    "# print(glob.glob(pathToVectFolder + \"/*\"))\n",
    "\n",
    "# df['DT'] = y_bin_pred.tolist()\n",
    "# df['GB'] = np.random.randint(2, size=500).tolist()\n",
    "# df['MLP'] = np.random.randint(2, size=500).tolist()\n",
    "# df['RF'] = np.random.randint(2, size=500).tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irfan/virEnv375/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3524: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1287972, 3)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../datasets/disaster data.csv\"\n",
    "df = pd.read_csv(path , encoding = \"ISO-8859-1\")\n",
    "df.shape\n",
    "# df.iloc[:, 6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/irfan/새 볼륨/development/request_identification_ML/PretrainedTokenizerClf'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>tweet_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1  c2  c3  c4  tweet_class\n",
       "0   1   1   1   0            0\n",
       "1   2   1   2   2            2\n",
       "2   2   3   3   0            0\n",
       "3   2   0   0   0            0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_max_from_rows_into_column(df, indexes):\n",
    "    \"\"\" The function takes dataframe and index of columns, and \n",
    "    then it returns the array containg the most frequent value against each row.\n",
    "    Example: \n",
    "    dataframe:\n",
    "    'c1' | 'c2'| 'c3' | 'c4'\n",
    "    -------------------------\n",
    "      1  |  1  |   1  |  0  \n",
    "      2  |  1  |   2  |  2\n",
    "      2  |  3  |   3  |  0 \n",
    "      2  |  0  |   0  |  0 \n",
    "      returned array:\n",
    "      (1, 2, 3, 0)\n",
    "      df: dataframe\n",
    "      indexes: indexes of columns\n",
    "      example: get_max_from_rows_into_column(dataframe, -3:)\n",
    "      \"\"\"\n",
    "    def get_array(df):\n",
    "        max_unique_label_column = np.empty([0])\n",
    "        for v in df.values:\n",
    "            unique_label, freq_label = np.unique(v, return_counts=True)\n",
    "            # print(unique_label[np.argmax(freq_label)])\n",
    "            max_unique_label_column = np.append(max_unique_label_column, unique_label[np.argmax(freq_label)])\n",
    "            \n",
    "        return max_unique_label_column\n",
    "    if \":\" in indexes:\n",
    "        if indexes[0] == \":\":\n",
    "            \n",
    "            df = df.iloc[:, :int(indexes[1:])]\n",
    "            max_unique_label_column = get_array(df)\n",
    "        if indexes[-1] == \":\":\n",
    "            df = df.iloc[:, int(indexes[:-1]):]\n",
    "            max_unique_label_column = get_array(df)\n",
    "           \n",
    "        else:\n",
    "            indexes = [int(x) for x in indexes.split(\":\")]\n",
    "            df = df.iloc[:, indexes[0]: indexes[1]]\n",
    "            max_unique_label_column = get_array(df)\n",
    "    else:\n",
    "            indexes = [int(x) for x in indexes.split(\",\")]\n",
    "            df = df.iloc[:, indexes]\n",
    "            max_unique_label_column = get_array(df)\n",
    "    return max_unique_label_column.astype(int)\n",
    "#     for v in df.iloc[:, indexes].values:\n",
    "#         unique_label, freq_label = np.unique(v, return_counts=True)\n",
    "#         print(unique_label)\n",
    "#         print(freq_label)\n",
    "#         print(unique_label[np.argmax(freq_label)])\n",
    "#     #     print(counts.indexOf(max(counts)))\n",
    "    #     print(unique)\n",
    "\n",
    "#         print(40*\"*\")\n",
    "\n",
    "d = {'c1': [1, 2, 2, 2], 'c2': [1, 1, 3, 0], 'c3': [1, 2, 3, 0], 'c4': [0, 2, 0, 0]}\n",
    "# path = \"../datasets/500_random_sample_withPredictions_withPredictions.csv\"\n",
    "# df = pd.read_csv(path , encoding = \"ISO-8859-1\")\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "indexes = \"2:\"\n",
    "df[\"tweet_class\"] = get_max_from_rows_into_column(df, indexes)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    434\n",
       "1.0     66\n",
       "Name: new, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_max_from_rows_into_column(df, indexes):\n",
    "    \"\"\" The function takes dataframe and index of columns, and \n",
    "    then it returns the array containg the most frequent value against each row.\n",
    "    Example: \n",
    "    dataframe:\n",
    "    'c1' | 'c2'| 'c3' | 'c4'\n",
    "    -------------------------\n",
    "      1  |  1  |   1  |  0  \n",
    "      2  |  1  |   2  |  2\n",
    "      2  |  3  |   3  |  0 \n",
    "      2  |  0  |   0  |  0 \n",
    "      returned array:\n",
    "      (1, 2, 3, 0)\n",
    "      df: dataframe\n",
    "      indexes: indexes of columns\n",
    "      example: get_max_from_rows_into_column(dataframe, -3:)\n",
    "      \"\"\"\n",
    "    def get_array(df):\n",
    "        max_unique_label_column = np.empty([0])\n",
    "        for v in df.values:\n",
    "            unique_label, freq_label = np.unique(v, return_counts=True)\n",
    "            # print(unique_label[np.argmax(freq_label)])\n",
    "            max_unique_label_column = np.append(max_unique_label_column, unique_label[np.argmax(freq_label)])\n",
    "            \n",
    "        return max_unique_label_column\n",
    "    if \":\" in indexes:\n",
    "        if indexes[0] == \":\":\n",
    "            \n",
    "            df = df.iloc[:, :int(indexes[1:])]\n",
    "            max_unique_label_column = get_array(df)\n",
    "        if indexes[-1] == \":\":\n",
    "            df = df.iloc[:, int(indexes[:-1]):]\n",
    "            max_unique_label_column = get_array(df)\n",
    "           \n",
    "        else:\n",
    "            indexes = [int(x) for x in indexes.split(\":\")]\n",
    "            df = df.iloc[:, indexes[0]: indexes[1]]\n",
    "            max_unique_label_column = get_array(df)\n",
    "    else:\n",
    "            indexes = [int(x) for x in indexes.split(\",\")]\n",
    "            df = df.iloc[:, indexes]\n",
    "            max_unique_label_column = get_array(df)\n",
    "    return max_unique_label_column.astype(int)\n",
    "\n",
    "\n",
    "path = \"500_random_sample_withPredictions_withPredictions_withPredictions.csv\"\n",
    "df = pd.read_csv(path,  encoding = \"ISO-8859-1\")\n",
    "\n",
    "indexes = \"4:\"\n",
    "df[\"tweet_class\"] = get_max_from_rows_into_column(df, indexes)\n",
    "df = df[[\"tweetID\", \"tweet_text\", \"tweet_class\"]]\n",
    "df.to_csv(\"disaster data.csv\", index=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['DT'] = y_bin_pred.tolist()\n",
    "df['GB'] = np.random.randint(2, size=500).tolist()\n",
    "df['MLP'] = np.random.randint(2, size=500).tolist()\n",
    "df['RF'] = np.random.randint(2, size=500).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"request\"] = df.iloc[:, -4:].mean(axis=1) > 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>GB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DT  GB  MLP  RF\n",
       "0     0   0    1   0\n",
       "1     1   0    1   1\n",
       "2     0   1    1   1\n",
       "3     0   1    1   1\n",
       "4     0   1    0   0\n",
       "..   ..  ..  ...  ..\n",
       "495   1   0    0   1\n",
       "496   0   0    1   1\n",
       "497   0   0    1   1\n",
       "498   0   1    0   1\n",
       "499   0   0    0   1\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, -4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "e = np.empty([0])\n",
    "e = np.append(e, 1)\n",
    "e = np.append(e, 2)\n",
    "e = np.append(e, 3)\n",
    "print(list(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [2, 2],\n",
       "       [3, 0],\n",
       "       [0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, -2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>RF</th>\n",
       "      <th>num_uniq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GB  MLP  RF  num_uniq\n",
       "0     0    1   1         4\n",
       "1     0    0   0         4\n",
       "2     0    0   0         4\n",
       "3     1    1   0         4\n",
       "4     1    1   1         4\n",
       "..   ..  ...  ..       ...\n",
       "495   0    0   0         4\n",
       "496   1    0   1         4\n",
       "497   0    0   0         4\n",
       "498   0    0   0         4\n",
       "499   0    0   1         4\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, -:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "[1. 2. 3. 0.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1  c2  c3  c4  new\n",
       "0   1   1   1   0  1.0\n",
       "1   2   1   2   2  2.0\n",
       "2   2   3   3   0  3.0\n",
       "3   2   0   0   0  0.0"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4:-3\n",
      "[-4, -3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>GB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DT  GB\n",
       "0     0   0\n",
       "1     1   0\n",
       "2     0   1\n",
       "3     0   1\n",
       "4     0   1\n",
       "..   ..  ..\n",
       "495   1   0\n",
       "496   0   0\n",
       "497   0   0\n",
       "498   0   1\n",
       "499   0   0\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = \"-4:-3\"\n",
    "print(indexes)\n",
    "if \":\" in indexes:\n",
    "    if indexes[0] == \":\" or indexes[-1] == \":\":\n",
    "        indexes = indexes\n",
    "    else:\n",
    "        indexes = [int(x) for x in indexes.split(\":\")]\n",
    "        return\n",
    "else:\n",
    "    indexes = [int(x) for x in indexes.split(\",\")]\n",
    "print(indexes)\n",
    "df.iloc[:, indexes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1  c2  c3  c4\n",
       "0   1   1   1   0\n",
       "1   2   1   2   0\n",
       "2   2   3   2   0\n",
       "3   2   0   0   0"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'c1': [1, 2, 2, 2], 'c2': [1, 1, 3, 0], 'c3': [1, 2, 2, 0], 'c4': [0, 2, 0, 0]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-299-fb0fb3b0f8c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-299-fb0fb3b0f8c9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "[int(x) for x in indexes.split(\":\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-433'"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = \":-433\"\n",
    "indexes[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "495    1\n",
       "496    0\n",
       "497    0\n",
       "498    0\n",
       "499    0\n",
       "Name: DT, Length: 500, dtype: int64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, -4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>GB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DT  GB  MLP  RF\n",
       "0     0   0    1   0\n",
       "1     1   0    1   1\n",
       "2     0   1    1   1\n",
       "3     0   1    1   1\n",
       "4     0   1    0   0\n",
       "..   ..  ..  ...  ..\n",
       "495   1   0    0   1\n",
       "496   0   0    1   1\n",
       "497   0   0    1   1\n",
       "498   0   1    0   1\n",
       "499   0   0    0   1\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, -4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_uniq'] = [len(set(v[pd.notna(v)].tolist())) for v in df.iloc[:, -4:].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_uniq'] = df.iloc[:, -4:].stack().groupby(level=0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      4\n",
       "1      4\n",
       "2      4\n",
       "3      4\n",
       "4      4\n",
       "      ..\n",
       "495    4\n",
       "496    4\n",
       "497    4\n",
       "498    4\n",
       "499    4\n",
       "Name: num_uniq, Length: 500, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(array, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([11, 12, 13, 14, 15, 16, 17, 15, 11, 12, 14, 15, 16, 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 12, 13, 14, 15, 16, 17, 15, 11, 12, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/irfan/새 볼륨/development/request_identification_ML/PretrainedTokenizerClf'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virEnv375",
   "language": "python",
   "name": "virenv375"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
